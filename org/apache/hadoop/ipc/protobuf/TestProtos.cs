// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: test.proto
using Sharpen;

namespace org.apache.hadoop.ipc.protobuf
{
	public sealed class TestProtos
	{
		private TestProtos()
		{
		}

		public static void registerAllExtensions(com.google.protobuf.ExtensionRegistry registry
			)
		{
		}

		public interface EmptyRequestProtoOrBuilder : com.google.protobuf.MessageOrBuilder
		{
		}

		/// <summary>
		/// Protobuf type
		/// <c>hadoop.common.EmptyRequestProto</c>
		/// </summary>
		[System.Serializable]
		public sealed class EmptyRequestProto : com.google.protobuf.GeneratedMessage, org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProtoOrBuilder
		{
			private EmptyRequestProto(com.google.protobuf.GeneratedMessage.Builder<object> builder
				)
				: base(builder)
			{
				// Use EmptyRequestProto.newBuilder() to construct.
				this.unknownFields = builder.getUnknownFields();
			}

			private EmptyRequestProto(bool noInit)
			{
				this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
			}

			private static readonly org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
				 defaultInstance;

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto getDefaultInstance
				()
			{
				return defaultInstance;
			}

			public override com.google.protobuf.MessageLite getDefaultInstanceForType()
			{
				return defaultInstance;
			}

			private readonly com.google.protobuf.UnknownFieldSet unknownFields;

			public sealed override com.google.protobuf.UnknownFieldSet getUnknownFields()
			{
				return this.unknownFields;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			private EmptyRequestProto(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				initFields();
				com.google.protobuf.UnknownFieldSet.Builder unknownFields = com.google.protobuf.UnknownFieldSet
					.newBuilder();
				try
				{
					bool done = false;
					while (!done)
					{
						int tag = input.readTag();
						switch (tag)
						{
							case 0:
							{
								done = true;
								break;
							}

							default:
							{
								if (!parseUnknownField(input, unknownFields, extensionRegistry, tag))
								{
									done = true;
								}
								break;
							}
						}
					}
				}
				catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					throw e.setUnfinishedMessage(this);
				}
				catch (System.IO.IOException e)
				{
					throw new com.google.protobuf.InvalidProtocolBufferException(e.Message).setUnfinishedMessage
						(this);
				}
				finally
				{
					this.unknownFields = unknownFields.build();
					makeExtensionsImmutable();
				}
			}

			public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_descriptor;
			}

			protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
				()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_fieldAccessorTable
					.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
					)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
					)));
			}

			private sealed class _AbstractParser_89 : com.google.protobuf.AbstractParser<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
				>
			{
				public _AbstractParser_89()
				{
				}

				/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parsePartialFrom
					(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto(input, extensionRegistry
						);
				}
			}

			public static com.google.protobuf.Parser<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
				> PARSER = new _AbstractParser_89();

			public override com.google.protobuf.Parser<com.google.protobuf.MessageLite> getParserForType
				()
			{
				return PARSER;
			}

			private void initFields()
			{
			}

			private byte memoizedIsInitialized = unchecked((byte)(-1));

			public sealed override bool isInitialized()
			{
				byte isInitialized = memoizedIsInitialized;
				if (isInitialized != -1)
				{
					return isInitialized == 1;
				}
				memoizedIsInitialized = 1;
				return true;
			}

			/// <exception cref="System.IO.IOException"/>
			public override void writeTo(com.google.protobuf.CodedOutputStream output)
			{
				getSerializedSize();
				getUnknownFields().writeTo(output);
			}

			private int memoizedSerializedSize = -1;

			public override int getSerializedSize()
			{
				int size = memoizedSerializedSize;
				if (size != -1)
				{
					return size;
				}
				size = 0;
				size += getUnknownFields().getSerializedSize();
				memoizedSerializedSize = size;
				return size;
			}

			private const long serialVersionUID = 0L;

			/// <exception cref="java.io.ObjectStreamException"/>
			protected override object writeReplace()
			{
				return base.writeReplace();
			}

			public override bool Equals(object obj)
			{
				if (obj == this)
				{
					return true;
				}
				if (!(obj is org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto))
				{
					return base.Equals(obj);
				}
				org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto other = (org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
					)obj;
				bool result = true;
				result = result && getUnknownFields().Equals(other.getUnknownFields());
				return result;
			}

			private int memoizedHashCode = 0;

			public override int GetHashCode()
			{
				if (memoizedHashCode != 0)
				{
					return memoizedHashCode;
				}
				int hash = 41;
				hash = (19 * hash) + getDescriptorForType().GetHashCode();
				hash = (29 * hash) + getUnknownFields().GetHashCode();
				memoizedHashCode = hash;
				return hash;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(com.google.protobuf.ByteString data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite 
				extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(byte[] data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(java.io.InputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseDelimitedFrom
				(java.io.InputStream input)
			{
				return PARSER.parseDelimitedFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseDelimitedFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseDelimitedFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(com.google.protobuf.CodedInputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parseFrom
				(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
				 newBuilder()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder.create
					();
			}

			public override com.google.protobuf.MessageLite.Builder newBuilderForType()
			{
				return newBuilder();
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
				 newBuilder(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto prototype
				)
			{
				return newBuilder().mergeFrom(prototype);
			}

			public override com.google.protobuf.MessageLite.Builder toBuilder()
			{
				return newBuilder(this);
			}

			protected override com.google.protobuf.Message.Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent
				 parent)
			{
				org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder builder = new 
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder(parent);
				return builder;
			}

			/// <summary>
			/// Protobuf type
			/// <c>hadoop.common.EmptyRequestProto</c>
			/// </summary>
			public sealed class Builder : com.google.protobuf.GeneratedMessage.Builder<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
				>, org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProtoOrBuilder
			{
				public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_descriptor;
				}

				protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
					()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_fieldAccessorTable
						.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
						)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
						)));
				}

				private Builder()
				{
					// Construct using org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.newBuilder()
					maybeForceBuilderInitialization();
				}

				private Builder(com.google.protobuf.GeneratedMessage.BuilderParent parent)
					: base(parent)
				{
					maybeForceBuilderInitialization();
				}

				private void maybeForceBuilderInitialization()
				{
					if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
					{
					}
				}

				private static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
					 create()
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder();
				}

				public override com.google.protobuf.MessageLite.Builder clear()
				{
					base.clear();
					return this;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
					 clone()
				{
					return create().mergeFrom(((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
						)buildPartial()));
				}

				public override com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_descriptor;
				}

				public override com.google.protobuf.MessageLite getDefaultInstanceForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.getDefaultInstance
						();
				}

				public override com.google.protobuf.MessageLite build()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto result = ((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
						)buildPartial());
					if (!result.isInitialized())
					{
						throw newUninitializedMessageException(result);
					}
					return result;
				}

				public override com.google.protobuf.MessageLite buildPartial()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto result = new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
						(this);
					onBuilt();
					return result;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
					 mergeFrom(com.google.protobuf.Message other)
				{
					if (other is org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto)
					{
						return mergeFrom((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto)other
							);
					}
					else
					{
						base.mergeFrom(other);
						return this;
					}
				}

				public org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder mergeFrom
					(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto other)
				{
					if (other == org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.getDefaultInstance
						())
					{
						return this;
					}
					this.mergeUnknownFields(other.getUnknownFields());
					return this;
				}

				public sealed override bool isInitialized()
				{
					return true;
				}

				/// <exception cref="System.IO.IOException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto.Builder
					 mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto parsedMessage = null;
					try
					{
						parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
					}
					catch (com.google.protobuf.InvalidProtocolBufferException e)
					{
						parsedMessage = (org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto)e.getUnfinishedMessage
							();
						throw;
					}
					finally
					{
						if (parsedMessage != null)
						{
							mergeFrom(parsedMessage);
						}
					}
					return this;
				}
				// @@protoc_insertion_point(builder_scope:hadoop.common.EmptyRequestProto)
			}

			static EmptyRequestProto()
			{
				defaultInstance = new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyRequestProto
					(true);
				defaultInstance.initFields();
			}
			// @@protoc_insertion_point(class_scope:hadoop.common.EmptyRequestProto)
		}

		public interface EmptyResponseProtoOrBuilder : com.google.protobuf.MessageOrBuilder
		{
		}

		/// <summary>
		/// Protobuf type
		/// <c>hadoop.common.EmptyResponseProto</c>
		/// </summary>
		[System.Serializable]
		public sealed class EmptyResponseProto : com.google.protobuf.GeneratedMessage, org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProtoOrBuilder
		{
			private EmptyResponseProto(com.google.protobuf.GeneratedMessage.Builder<object> builder
				)
				: base(builder)
			{
				// Use EmptyResponseProto.newBuilder() to construct.
				this.unknownFields = builder.getUnknownFields();
			}

			private EmptyResponseProto(bool noInit)
			{
				this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
			}

			private static readonly org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
				 defaultInstance;

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto getDefaultInstance
				()
			{
				return defaultInstance;
			}

			public override com.google.protobuf.MessageLite getDefaultInstanceForType()
			{
				return defaultInstance;
			}

			private readonly com.google.protobuf.UnknownFieldSet unknownFields;

			public sealed override com.google.protobuf.UnknownFieldSet getUnknownFields()
			{
				return this.unknownFields;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			private EmptyResponseProto(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				initFields();
				com.google.protobuf.UnknownFieldSet.Builder unknownFields = com.google.protobuf.UnknownFieldSet
					.newBuilder();
				try
				{
					bool done = false;
					while (!done)
					{
						int tag = input.readTag();
						switch (tag)
						{
							case 0:
							{
								done = true;
								break;
							}

							default:
							{
								if (!parseUnknownField(input, unknownFields, extensionRegistry, tag))
								{
									done = true;
								}
								break;
							}
						}
					}
				}
				catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					throw e.setUnfinishedMessage(this);
				}
				catch (System.IO.IOException e)
				{
					throw new com.google.protobuf.InvalidProtocolBufferException(e.Message).setUnfinishedMessage
						(this);
				}
				finally
				{
					this.unknownFields = unknownFields.build();
					makeExtensionsImmutable();
				}
			}

			public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_descriptor;
			}

			protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
				()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_fieldAccessorTable
					.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
					)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
					)));
			}

			private sealed class _AbstractParser_427 : com.google.protobuf.AbstractParser<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
				>
			{
				public _AbstractParser_427()
				{
				}

				/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parsePartialFrom
					(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto(input, extensionRegistry
						);
				}
			}

			public static com.google.protobuf.Parser<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
				> PARSER = new _AbstractParser_427();

			public override com.google.protobuf.Parser<com.google.protobuf.MessageLite> getParserForType
				()
			{
				return PARSER;
			}

			private void initFields()
			{
			}

			private byte memoizedIsInitialized = unchecked((byte)(-1));

			public sealed override bool isInitialized()
			{
				byte isInitialized = memoizedIsInitialized;
				if (isInitialized != -1)
				{
					return isInitialized == 1;
				}
				memoizedIsInitialized = 1;
				return true;
			}

			/// <exception cref="System.IO.IOException"/>
			public override void writeTo(com.google.protobuf.CodedOutputStream output)
			{
				getSerializedSize();
				getUnknownFields().writeTo(output);
			}

			private int memoizedSerializedSize = -1;

			public override int getSerializedSize()
			{
				int size = memoizedSerializedSize;
				if (size != -1)
				{
					return size;
				}
				size = 0;
				size += getUnknownFields().getSerializedSize();
				memoizedSerializedSize = size;
				return size;
			}

			private const long serialVersionUID = 0L;

			/// <exception cref="java.io.ObjectStreamException"/>
			protected override object writeReplace()
			{
				return base.writeReplace();
			}

			public override bool Equals(object obj)
			{
				if (obj == this)
				{
					return true;
				}
				if (!(obj is org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto))
				{
					return base.Equals(obj);
				}
				org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto other = (org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
					)obj;
				bool result = true;
				result = result && getUnknownFields().Equals(other.getUnknownFields());
				return result;
			}

			private int memoizedHashCode = 0;

			public override int GetHashCode()
			{
				if (memoizedHashCode != 0)
				{
					return memoizedHashCode;
				}
				int hash = 41;
				hash = (19 * hash) + getDescriptorForType().GetHashCode();
				hash = (29 * hash) + getUnknownFields().GetHashCode();
				memoizedHashCode = hash;
				return hash;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(com.google.protobuf.ByteString data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite 
				extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(byte[] data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(java.io.InputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseDelimitedFrom
				(java.io.InputStream input)
			{
				return PARSER.parseDelimitedFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseDelimitedFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseDelimitedFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(com.google.protobuf.CodedInputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parseFrom
				(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
				 newBuilder()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder.create
					();
			}

			public override com.google.protobuf.MessageLite.Builder newBuilderForType()
			{
				return newBuilder();
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
				 newBuilder(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto prototype
				)
			{
				return newBuilder().mergeFrom(prototype);
			}

			public override com.google.protobuf.MessageLite.Builder toBuilder()
			{
				return newBuilder(this);
			}

			protected override com.google.protobuf.Message.Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent
				 parent)
			{
				org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder builder = new 
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder(parent);
				return builder;
			}

			/// <summary>
			/// Protobuf type
			/// <c>hadoop.common.EmptyResponseProto</c>
			/// </summary>
			public sealed class Builder : com.google.protobuf.GeneratedMessage.Builder<org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
				>, org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProtoOrBuilder
			{
				public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_descriptor;
				}

				protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
					()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_fieldAccessorTable
						.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
						)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
						)));
				}

				private Builder()
				{
					// Construct using org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.newBuilder()
					maybeForceBuilderInitialization();
				}

				private Builder(com.google.protobuf.GeneratedMessage.BuilderParent parent)
					: base(parent)
				{
					maybeForceBuilderInitialization();
				}

				private void maybeForceBuilderInitialization()
				{
					if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
					{
					}
				}

				private static org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
					 create()
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder();
				}

				public override com.google.protobuf.MessageLite.Builder clear()
				{
					base.clear();
					return this;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
					 clone()
				{
					return create().mergeFrom(((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
						)buildPartial()));
				}

				public override com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_descriptor;
				}

				public override com.google.protobuf.MessageLite getDefaultInstanceForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.getDefaultInstance
						();
				}

				public override com.google.protobuf.MessageLite build()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto result = ((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
						)buildPartial());
					if (!result.isInitialized())
					{
						throw newUninitializedMessageException(result);
					}
					return result;
				}

				public override com.google.protobuf.MessageLite buildPartial()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto result = new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
						(this);
					onBuilt();
					return result;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
					 mergeFrom(com.google.protobuf.Message other)
				{
					if (other is org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto)
					{
						return mergeFrom((org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto)other
							);
					}
					else
					{
						base.mergeFrom(other);
						return this;
					}
				}

				public org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder mergeFrom
					(org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto other)
				{
					if (other == org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.getDefaultInstance
						())
					{
						return this;
					}
					this.mergeUnknownFields(other.getUnknownFields());
					return this;
				}

				public sealed override bool isInitialized()
				{
					return true;
				}

				/// <exception cref="System.IO.IOException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto.Builder
					 mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto parsedMessage = null;
					try
					{
						parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
					}
					catch (com.google.protobuf.InvalidProtocolBufferException e)
					{
						parsedMessage = (org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto)e.getUnfinishedMessage
							();
						throw;
					}
					finally
					{
						if (parsedMessage != null)
						{
							mergeFrom(parsedMessage);
						}
					}
					return this;
				}
				// @@protoc_insertion_point(builder_scope:hadoop.common.EmptyResponseProto)
			}

			static EmptyResponseProto()
			{
				defaultInstance = new org.apache.hadoop.ipc.protobuf.TestProtos.EmptyResponseProto
					(true);
				defaultInstance.initFields();
			}
			// @@protoc_insertion_point(class_scope:hadoop.common.EmptyResponseProto)
		}

		public interface EchoRequestProtoOrBuilder : com.google.protobuf.MessageOrBuilder
		{
			// required string message = 1;
			/// <summary><code>required string message = 1;</code></summary>
			bool hasMessage();

			/// <summary><code>required string message = 1;</code></summary>
			string getMessage();

			/// <summary><code>required string message = 1;</code></summary>
			com.google.protobuf.ByteString getMessageBytes();
		}

		/// <summary>
		/// Protobuf type
		/// <c>hadoop.common.EchoRequestProto</c>
		/// </summary>
		[System.Serializable]
		public sealed class EchoRequestProto : com.google.protobuf.GeneratedMessage, org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProtoOrBuilder
		{
			private EchoRequestProto(com.google.protobuf.GeneratedMessage.Builder<object> builder
				)
				: base(builder)
			{
				// Use EchoRequestProto.newBuilder() to construct.
				this.unknownFields = builder.getUnknownFields();
			}

			private EchoRequestProto(bool noInit)
			{
				this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
			}

			private static readonly org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
				 defaultInstance;

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto getDefaultInstance
				()
			{
				return defaultInstance;
			}

			public override com.google.protobuf.MessageLite getDefaultInstanceForType()
			{
				return defaultInstance;
			}

			private readonly com.google.protobuf.UnknownFieldSet unknownFields;

			public sealed override com.google.protobuf.UnknownFieldSet getUnknownFields()
			{
				return this.unknownFields;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			private EchoRequestProto(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				initFields();
				int mutable_bitField0_ = 0;
				com.google.protobuf.UnknownFieldSet.Builder unknownFields = com.google.protobuf.UnknownFieldSet
					.newBuilder();
				try
				{
					bool done = false;
					while (!done)
					{
						int tag = input.readTag();
						switch (tag)
						{
							case 0:
							{
								done = true;
								break;
							}

							default:
							{
								if (!parseUnknownField(input, unknownFields, extensionRegistry, tag))
								{
									done = true;
								}
								break;
							}

							case 10:
							{
								bitField0_ |= unchecked((int)(0x00000001));
								message_ = input.readBytes();
								break;
							}
						}
					}
				}
				catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					throw e.setUnfinishedMessage(this);
				}
				catch (System.IO.IOException e)
				{
					throw new com.google.protobuf.InvalidProtocolBufferException(e.Message).setUnfinishedMessage
						(this);
				}
				finally
				{
					this.unknownFields = unknownFields.build();
					makeExtensionsImmutable();
				}
			}

			public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_descriptor;
			}

			protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
				()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_fieldAccessorTable
					.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
					)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
					)));
			}

			private sealed class _AbstractParser_786 : com.google.protobuf.AbstractParser<org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
				>
			{
				public _AbstractParser_786()
				{
				}

				/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parsePartialFrom
					(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto(input, extensionRegistry
						);
				}
			}

			public static com.google.protobuf.Parser<org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
				> PARSER = new _AbstractParser_786();

			public override com.google.protobuf.Parser<com.google.protobuf.MessageLite> getParserForType
				()
			{
				return PARSER;
			}

			private int bitField0_;

			public const int MESSAGE_FIELD_NUMBER = 1;

			private object message_;

			// required string message = 1;
			/// <summary><code>required string message = 1;</code></summary>
			public bool hasMessage()
			{
				return ((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
					)));
			}

			/// <summary><code>required string message = 1;</code></summary>
			public string getMessage()
			{
				object @ref = message_;
				if (@ref is string)
				{
					return (string)@ref;
				}
				else
				{
					com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)@ref;
					string s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						message_ = s;
					}
					return s;
				}
			}

			/// <summary><code>required string message = 1;</code></summary>
			public com.google.protobuf.ByteString getMessageBytes()
			{
				object @ref = message_;
				if (@ref is string)
				{
					com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((string
						)@ref);
					message_ = b;
					return b;
				}
				else
				{
					return (com.google.protobuf.ByteString)@ref;
				}
			}

			private void initFields()
			{
				message_ = string.Empty;
			}

			private byte memoizedIsInitialized = unchecked((byte)(-1));

			public sealed override bool isInitialized()
			{
				byte isInitialized = memoizedIsInitialized;
				if (isInitialized != -1)
				{
					return isInitialized == 1;
				}
				if (!hasMessage())
				{
					memoizedIsInitialized = 0;
					return false;
				}
				memoizedIsInitialized = 1;
				return true;
			}

			/// <exception cref="System.IO.IOException"/>
			public override void writeTo(com.google.protobuf.CodedOutputStream output)
			{
				getSerializedSize();
				if (((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001))))
				{
					output.writeBytes(1, getMessageBytes());
				}
				getUnknownFields().writeTo(output);
			}

			private int memoizedSerializedSize = -1;

			public override int getSerializedSize()
			{
				int size = memoizedSerializedSize;
				if (size != -1)
				{
					return size;
				}
				size = 0;
				if (((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001))))
				{
					size += com.google.protobuf.CodedOutputStream.computeBytesSize(1, getMessageBytes
						());
				}
				size += getUnknownFields().getSerializedSize();
				memoizedSerializedSize = size;
				return size;
			}

			private const long serialVersionUID = 0L;

			/// <exception cref="java.io.ObjectStreamException"/>
			protected override object writeReplace()
			{
				return base.writeReplace();
			}

			public override bool Equals(object obj)
			{
				if (obj == this)
				{
					return true;
				}
				if (!(obj is org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto))
				{
					return base.Equals(obj);
				}
				org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto other = (org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
					)obj;
				bool result = true;
				result = result && (hasMessage() == other.hasMessage());
				if (hasMessage())
				{
					result = result && getMessage().Equals(other.getMessage());
				}
				result = result && getUnknownFields().Equals(other.getUnknownFields());
				return result;
			}

			private int memoizedHashCode = 0;

			public override int GetHashCode()
			{
				if (memoizedHashCode != 0)
				{
					return memoizedHashCode;
				}
				int hash = 41;
				hash = (19 * hash) + getDescriptorForType().GetHashCode();
				if (hasMessage())
				{
					hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
					hash = (53 * hash) + getMessage().GetHashCode();
				}
				hash = (29 * hash) + getUnknownFields().GetHashCode();
				memoizedHashCode = hash;
				return hash;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(com.google.protobuf.ByteString data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite 
				extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(byte[] data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(java.io.InputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseDelimitedFrom
				(java.io.InputStream input)
			{
				return PARSER.parseDelimitedFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseDelimitedFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseDelimitedFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(com.google.protobuf.CodedInputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parseFrom
				(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder 
				newBuilder()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder.create(
					);
			}

			public override com.google.protobuf.MessageLite.Builder newBuilderForType()
			{
				return newBuilder();
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder 
				newBuilder(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto prototype)
			{
				return newBuilder().mergeFrom(prototype);
			}

			public override com.google.protobuf.MessageLite.Builder toBuilder()
			{
				return newBuilder(this);
			}

			protected override com.google.protobuf.Message.Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent
				 parent)
			{
				org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder builder = new 
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder(parent);
				return builder;
			}

			/// <summary>
			/// Protobuf type
			/// <c>hadoop.common.EchoRequestProto</c>
			/// </summary>
			public sealed class Builder : com.google.protobuf.GeneratedMessage.Builder<org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
				>, org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProtoOrBuilder
			{
				public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_descriptor;
				}

				protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
					()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_fieldAccessorTable
						.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
						)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
						)));
				}

				private Builder()
				{
					// Construct using org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.newBuilder()
					maybeForceBuilderInitialization();
				}

				private Builder(com.google.protobuf.GeneratedMessage.BuilderParent parent)
					: base(parent)
				{
					maybeForceBuilderInitialization();
				}

				private void maybeForceBuilderInitialization()
				{
					if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
					{
					}
				}

				private static org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
					 create()
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder();
				}

				public override com.google.protobuf.MessageLite.Builder clear()
				{
					base.clear();
					message_ = string.Empty;
					bitField0_ = (bitField0_ & ~unchecked((int)(0x00000001)));
					return this;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
					 clone()
				{
					return create().mergeFrom(((org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
						)buildPartial()));
				}

				public override com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_descriptor;
				}

				public override com.google.protobuf.MessageLite getDefaultInstanceForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.getDefaultInstance
						();
				}

				public override com.google.protobuf.MessageLite build()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto result = ((org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
						)buildPartial());
					if (!result.isInitialized())
					{
						throw newUninitializedMessageException(result);
					}
					return result;
				}

				public override com.google.protobuf.MessageLite buildPartial()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto result = new org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto
						(this);
					int from_bitField0_ = bitField0_;
					int to_bitField0_ = 0;
					if (((from_bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
						))))
					{
						to_bitField0_ |= unchecked((int)(0x00000001));
					}
					result.message_ = message_;
					result.bitField0_ = to_bitField0_;
					onBuilt();
					return result;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
					 mergeFrom(com.google.protobuf.Message other)
				{
					if (other is org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto)
					{
						return mergeFrom((org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto)other
							);
					}
					else
					{
						base.mergeFrom(other);
						return this;
					}
				}

				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder mergeFrom
					(org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto other)
				{
					if (other == org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.getDefaultInstance
						())
					{
						return this;
					}
					if (other.hasMessage())
					{
						bitField0_ |= unchecked((int)(0x00000001));
						message_ = other.message_;
						onChanged();
					}
					this.mergeUnknownFields(other.getUnknownFields());
					return this;
				}

				public sealed override bool isInitialized()
				{
					if (!hasMessage())
					{
						return false;
					}
					return true;
				}

				/// <exception cref="System.IO.IOException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder
					 mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto parsedMessage = null;
					try
					{
						parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
					}
					catch (com.google.protobuf.InvalidProtocolBufferException e)
					{
						parsedMessage = (org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto)e.getUnfinishedMessage
							();
						throw;
					}
					finally
					{
						if (parsedMessage != null)
						{
							mergeFrom(parsedMessage);
						}
					}
					return this;
				}

				private int bitField0_;

				private object message_ = string.Empty;

				// required string message = 1;
				/// <summary><code>required string message = 1;</code></summary>
				public bool hasMessage()
				{
					return ((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
						)));
				}

				/// <summary><code>required string message = 1;</code></summary>
				public string getMessage()
				{
					object @ref = message_;
					if (!(@ref is string))
					{
						string s = ((com.google.protobuf.ByteString)@ref).toStringUtf8();
						message_ = s;
						return s;
					}
					else
					{
						return (string)@ref;
					}
				}

				/// <summary><code>required string message = 1;</code></summary>
				public com.google.protobuf.ByteString getMessageBytes()
				{
					object @ref = message_;
					if (@ref is string)
					{
						com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((string
							)@ref);
						message_ = b;
						return b;
					}
					else
					{
						return (com.google.protobuf.ByteString)@ref;
					}
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder setMessage
					(string value)
				{
					if (value == null)
					{
						throw new System.ArgumentNullException();
					}
					bitField0_ |= unchecked((int)(0x00000001));
					message_ = value;
					onChanged();
					return this;
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder clearMessage
					()
				{
					bitField0_ = (bitField0_ & ~unchecked((int)(0x00000001)));
					message_ = getDefaultInstance().getMessage();
					onChanged();
					return this;
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto.Builder setMessageBytes
					(com.google.protobuf.ByteString value)
				{
					if (value == null)
					{
						throw new System.ArgumentNullException();
					}
					bitField0_ |= unchecked((int)(0x00000001));
					message_ = value;
					onChanged();
					return this;
				}
				// @@protoc_insertion_point(builder_scope:hadoop.common.EchoRequestProto)
			}

			static EchoRequestProto()
			{
				defaultInstance = new org.apache.hadoop.ipc.protobuf.TestProtos.EchoRequestProto(
					true);
				defaultInstance.initFields();
			}
			// @@protoc_insertion_point(class_scope:hadoop.common.EchoRequestProto)
		}

		public interface EchoResponseProtoOrBuilder : com.google.protobuf.MessageOrBuilder
		{
			// required string message = 1;
			/// <summary><code>required string message = 1;</code></summary>
			bool hasMessage();

			/// <summary><code>required string message = 1;</code></summary>
			string getMessage();

			/// <summary><code>required string message = 1;</code></summary>
			com.google.protobuf.ByteString getMessageBytes();
		}

		/// <summary>
		/// Protobuf type
		/// <c>hadoop.common.EchoResponseProto</c>
		/// </summary>
		[System.Serializable]
		public sealed class EchoResponseProto : com.google.protobuf.GeneratedMessage, org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProtoOrBuilder
		{
			private EchoResponseProto(com.google.protobuf.GeneratedMessage.Builder<object> builder
				)
				: base(builder)
			{
				// Use EchoResponseProto.newBuilder() to construct.
				this.unknownFields = builder.getUnknownFields();
			}

			private EchoResponseProto(bool noInit)
			{
				this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance();
			}

			private static readonly org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
				 defaultInstance;

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto getDefaultInstance
				()
			{
				return defaultInstance;
			}

			public override com.google.protobuf.MessageLite getDefaultInstanceForType()
			{
				return defaultInstance;
			}

			private readonly com.google.protobuf.UnknownFieldSet unknownFields;

			public sealed override com.google.protobuf.UnknownFieldSet getUnknownFields()
			{
				return this.unknownFields;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			private EchoResponseProto(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				initFields();
				int mutable_bitField0_ = 0;
				com.google.protobuf.UnknownFieldSet.Builder unknownFields = com.google.protobuf.UnknownFieldSet
					.newBuilder();
				try
				{
					bool done = false;
					while (!done)
					{
						int tag = input.readTag();
						switch (tag)
						{
							case 0:
							{
								done = true;
								break;
							}

							default:
							{
								if (!parseUnknownField(input, unknownFields, extensionRegistry, tag))
								{
									done = true;
								}
								break;
							}

							case 10:
							{
								bitField0_ |= unchecked((int)(0x00000001));
								message_ = input.readBytes();
								break;
							}
						}
					}
				}
				catch (com.google.protobuf.InvalidProtocolBufferException e)
				{
					throw e.setUnfinishedMessage(this);
				}
				catch (System.IO.IOException e)
				{
					throw new com.google.protobuf.InvalidProtocolBufferException(e.Message).setUnfinishedMessage
						(this);
				}
				finally
				{
					this.unknownFields = unknownFields.build();
					makeExtensionsImmutable();
				}
			}

			public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_descriptor;
			}

			protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
				()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_fieldAccessorTable
					.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
					)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
					)));
			}

			private sealed class _AbstractParser_1303 : com.google.protobuf.AbstractParser<org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
				>
			{
				public _AbstractParser_1303()
				{
				}

				/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parsePartialFrom
					(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto(input, extensionRegistry
						);
				}
			}

			public static com.google.protobuf.Parser<org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
				> PARSER = new _AbstractParser_1303();

			public override com.google.protobuf.Parser<com.google.protobuf.MessageLite> getParserForType
				()
			{
				return PARSER;
			}

			private int bitField0_;

			public const int MESSAGE_FIELD_NUMBER = 1;

			private object message_;

			// required string message = 1;
			/// <summary><code>required string message = 1;</code></summary>
			public bool hasMessage()
			{
				return ((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
					)));
			}

			/// <summary><code>required string message = 1;</code></summary>
			public string getMessage()
			{
				object @ref = message_;
				if (@ref is string)
				{
					return (string)@ref;
				}
				else
				{
					com.google.protobuf.ByteString bs = (com.google.protobuf.ByteString)@ref;
					string s = bs.toStringUtf8();
					if (bs.isValidUtf8())
					{
						message_ = s;
					}
					return s;
				}
			}

			/// <summary><code>required string message = 1;</code></summary>
			public com.google.protobuf.ByteString getMessageBytes()
			{
				object @ref = message_;
				if (@ref is string)
				{
					com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((string
						)@ref);
					message_ = b;
					return b;
				}
				else
				{
					return (com.google.protobuf.ByteString)@ref;
				}
			}

			private void initFields()
			{
				message_ = string.Empty;
			}

			private byte memoizedIsInitialized = unchecked((byte)(-1));

			public sealed override bool isInitialized()
			{
				byte isInitialized = memoizedIsInitialized;
				if (isInitialized != -1)
				{
					return isInitialized == 1;
				}
				if (!hasMessage())
				{
					memoizedIsInitialized = 0;
					return false;
				}
				memoizedIsInitialized = 1;
				return true;
			}

			/// <exception cref="System.IO.IOException"/>
			public override void writeTo(com.google.protobuf.CodedOutputStream output)
			{
				getSerializedSize();
				if (((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001))))
				{
					output.writeBytes(1, getMessageBytes());
				}
				getUnknownFields().writeTo(output);
			}

			private int memoizedSerializedSize = -1;

			public override int getSerializedSize()
			{
				int size = memoizedSerializedSize;
				if (size != -1)
				{
					return size;
				}
				size = 0;
				if (((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001))))
				{
					size += com.google.protobuf.CodedOutputStream.computeBytesSize(1, getMessageBytes
						());
				}
				size += getUnknownFields().getSerializedSize();
				memoizedSerializedSize = size;
				return size;
			}

			private const long serialVersionUID = 0L;

			/// <exception cref="java.io.ObjectStreamException"/>
			protected override object writeReplace()
			{
				return base.writeReplace();
			}

			public override bool Equals(object obj)
			{
				if (obj == this)
				{
					return true;
				}
				if (!(obj is org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto))
				{
					return base.Equals(obj);
				}
				org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto other = (org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
					)obj;
				bool result = true;
				result = result && (hasMessage() == other.hasMessage());
				if (hasMessage())
				{
					result = result && getMessage().Equals(other.getMessage());
				}
				result = result && getUnknownFields().Equals(other.getUnknownFields());
				return result;
			}

			private int memoizedHashCode = 0;

			public override int GetHashCode()
			{
				if (memoizedHashCode != 0)
				{
					return memoizedHashCode;
				}
				int hash = 41;
				hash = (19 * hash) + getDescriptorForType().GetHashCode();
				if (hasMessage())
				{
					hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
					hash = (53 * hash) + getMessage().GetHashCode();
				}
				hash = (29 * hash) + getUnknownFields().GetHashCode();
				memoizedHashCode = hash;
				return hash;
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(com.google.protobuf.ByteString data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(com.google.protobuf.ByteString data, com.google.protobuf.ExtensionRegistryLite 
				extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(byte[] data)
			{
				return PARSER.parseFrom(data);
			}

			/// <exception cref="com.google.protobuf.InvalidProtocolBufferException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(byte[] data, com.google.protobuf.ExtensionRegistryLite extensionRegistry)
			{
				return PARSER.parseFrom(data, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(java.io.InputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseDelimitedFrom
				(java.io.InputStream input)
			{
				return PARSER.parseDelimitedFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseDelimitedFrom
				(java.io.InputStream input, com.google.protobuf.ExtensionRegistryLite extensionRegistry
				)
			{
				return PARSER.parseDelimitedFrom(input, extensionRegistry);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(com.google.protobuf.CodedInputStream input)
			{
				return PARSER.parseFrom(input);
			}

			/// <exception cref="System.IO.IOException"/>
			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parseFrom
				(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
				 extensionRegistry)
			{
				return PARSER.parseFrom(input, extensionRegistry);
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
				 newBuilder()
			{
				return org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder.create
					();
			}

			public override com.google.protobuf.MessageLite.Builder newBuilderForType()
			{
				return newBuilder();
			}

			public static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
				 newBuilder(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto prototype
				)
			{
				return newBuilder().mergeFrom(prototype);
			}

			public override com.google.protobuf.MessageLite.Builder toBuilder()
			{
				return newBuilder(this);
			}

			protected override com.google.protobuf.Message.Builder newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent
				 parent)
			{
				org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder builder = new 
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder(parent);
				return builder;
			}

			/// <summary>
			/// Protobuf type
			/// <c>hadoop.common.EchoResponseProto</c>
			/// </summary>
			public sealed class Builder : com.google.protobuf.GeneratedMessage.Builder<org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
				>, org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProtoOrBuilder
			{
				public static com.google.protobuf.Descriptors.Descriptor getDescriptor()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_descriptor;
				}

				protected override com.google.protobuf.GeneratedMessage.FieldAccessorTable internalGetFieldAccessorTable
					()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_fieldAccessorTable
						.ensureFieldAccessorsInitialized(Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
						)), Sharpen.Runtime.getClassForType(typeof(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
						)));
				}

				private Builder()
				{
					// Construct using org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.newBuilder()
					maybeForceBuilderInitialization();
				}

				private Builder(com.google.protobuf.GeneratedMessage.BuilderParent parent)
					: base(parent)
				{
					maybeForceBuilderInitialization();
				}

				private void maybeForceBuilderInitialization()
				{
					if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders)
					{
					}
				}

				private static org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
					 create()
				{
					return new org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder();
				}

				public override com.google.protobuf.MessageLite.Builder clear()
				{
					base.clear();
					message_ = string.Empty;
					bitField0_ = (bitField0_ & ~unchecked((int)(0x00000001)));
					return this;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
					 clone()
				{
					return create().mergeFrom(((org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
						)buildPartial()));
				}

				public override com.google.protobuf.Descriptors.Descriptor getDescriptorForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_descriptor;
				}

				public override com.google.protobuf.MessageLite getDefaultInstanceForType()
				{
					return org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.getDefaultInstance
						();
				}

				public override com.google.protobuf.MessageLite build()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto result = ((org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
						)buildPartial());
					if (!result.isInitialized())
					{
						throw newUninitializedMessageException(result);
					}
					return result;
				}

				public override com.google.protobuf.MessageLite buildPartial()
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto result = new org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
						(this);
					int from_bitField0_ = bitField0_;
					int to_bitField0_ = 0;
					if (((from_bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
						))))
					{
						to_bitField0_ |= unchecked((int)(0x00000001));
					}
					result.message_ = message_;
					result.bitField0_ = to_bitField0_;
					onBuilt();
					return result;
				}

				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
					 mergeFrom(com.google.protobuf.Message other)
				{
					if (other is org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto)
					{
						return mergeFrom((org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto)other
							);
					}
					else
					{
						base.mergeFrom(other);
						return this;
					}
				}

				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder mergeFrom
					(org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto other)
				{
					if (other == org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.getDefaultInstance
						())
					{
						return this;
					}
					if (other.hasMessage())
					{
						bitField0_ |= unchecked((int)(0x00000001));
						message_ = other.message_;
						onChanged();
					}
					this.mergeUnknownFields(other.getUnknownFields());
					return this;
				}

				public sealed override bool isInitialized()
				{
					if (!hasMessage())
					{
						return false;
					}
					return true;
				}

				/// <exception cref="System.IO.IOException"/>
				public override org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder
					 mergeFrom(com.google.protobuf.CodedInputStream input, com.google.protobuf.ExtensionRegistryLite
					 extensionRegistry)
				{
					org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto parsedMessage = null;
					try
					{
						parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
					}
					catch (com.google.protobuf.InvalidProtocolBufferException e)
					{
						parsedMessage = (org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto)e.getUnfinishedMessage
							();
						throw;
					}
					finally
					{
						if (parsedMessage != null)
						{
							mergeFrom(parsedMessage);
						}
					}
					return this;
				}

				private int bitField0_;

				private object message_ = string.Empty;

				// required string message = 1;
				/// <summary><code>required string message = 1;</code></summary>
				public bool hasMessage()
				{
					return ((bitField0_ & unchecked((int)(0x00000001))) == unchecked((int)(0x00000001
						)));
				}

				/// <summary><code>required string message = 1;</code></summary>
				public string getMessage()
				{
					object @ref = message_;
					if (!(@ref is string))
					{
						string s = ((com.google.protobuf.ByteString)@ref).toStringUtf8();
						message_ = s;
						return s;
					}
					else
					{
						return (string)@ref;
					}
				}

				/// <summary><code>required string message = 1;</code></summary>
				public com.google.protobuf.ByteString getMessageBytes()
				{
					object @ref = message_;
					if (@ref is string)
					{
						com.google.protobuf.ByteString b = com.google.protobuf.ByteString.copyFromUtf8((string
							)@ref);
						message_ = b;
						return b;
					}
					else
					{
						return (com.google.protobuf.ByteString)@ref;
					}
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder setMessage
					(string value)
				{
					if (value == null)
					{
						throw new System.ArgumentNullException();
					}
					bitField0_ |= unchecked((int)(0x00000001));
					message_ = value;
					onChanged();
					return this;
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder clearMessage
					()
				{
					bitField0_ = (bitField0_ & ~unchecked((int)(0x00000001)));
					message_ = getDefaultInstance().getMessage();
					onChanged();
					return this;
				}

				/// <summary><code>required string message = 1;</code></summary>
				public org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto.Builder setMessageBytes
					(com.google.protobuf.ByteString value)
				{
					if (value == null)
					{
						throw new System.ArgumentNullException();
					}
					bitField0_ |= unchecked((int)(0x00000001));
					message_ = value;
					onChanged();
					return this;
				}
				// @@protoc_insertion_point(builder_scope:hadoop.common.EchoResponseProto)
			}

			static EchoResponseProto()
			{
				defaultInstance = new org.apache.hadoop.ipc.protobuf.TestProtos.EchoResponseProto
					(true);
				defaultInstance.initFields();
			}
			// @@protoc_insertion_point(class_scope:hadoop.common.EchoResponseProto)
		}

		private static com.google.protobuf.Descriptors.Descriptor internal_static_hadoop_common_EmptyRequestProto_descriptor;

		private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_hadoop_common_EmptyRequestProto_fieldAccessorTable;

		private static com.google.protobuf.Descriptors.Descriptor internal_static_hadoop_common_EmptyResponseProto_descriptor;

		private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_hadoop_common_EmptyResponseProto_fieldAccessorTable;

		private static com.google.protobuf.Descriptors.Descriptor internal_static_hadoop_common_EchoRequestProto_descriptor;

		private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_hadoop_common_EchoRequestProto_fieldAccessorTable;

		private static com.google.protobuf.Descriptors.Descriptor internal_static_hadoop_common_EchoResponseProto_descriptor;

		private static com.google.protobuf.GeneratedMessage.FieldAccessorTable internal_static_hadoop_common_EchoResponseProto_fieldAccessorTable;

		public static com.google.protobuf.Descriptors.FileDescriptor getDescriptor()
		{
			return descriptor;
		}

		private static com.google.protobuf.Descriptors.FileDescriptor descriptor;

		static TestProtos()
		{
			string[] descriptorData = new string[] { "\n\ntest.proto\x16\rhadoop.common\"\x17\n\x15EmptyRequ"
				 + "estProto\"\x18\n\x16EmptyResponseProto\"#\n\x14EchoRe" + "questProto\x16\x11\n\x7message\x1e\x1 \x2(\t\"$\n\x15EchoRespo"
				 + "nseProto\x16\x11\n\x7message\x1e\x1 \x2(\tB/\n\x24org.apache." + "hadoop.ipc.protobufB\nTestProtos\xf0\x1\x1"
				 };
			com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner
				 = new _InternalDescriptorAssigner_1757();
			com.google.protobuf.Descriptors.FileDescriptor.internalBuildGeneratedFileFrom(descriptorData
				, new com.google.protobuf.Descriptors.FileDescriptor[] {  }, assigner);
		}

		private sealed class _InternalDescriptorAssigner_1757 : com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner
		{
			public _InternalDescriptorAssigner_1757()
			{
			}

			public com.google.protobuf.ExtensionRegistry assignDescriptors(com.google.protobuf.Descriptors.FileDescriptor
				 root)
			{
				org.apache.hadoop.ipc.protobuf.TestProtos.descriptor = root;
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_descriptor
					 = org.apache.hadoop.ipc.protobuf.TestProtos.getDescriptor().getMessageTypes()[0
					];
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyRequestProto_fieldAccessorTable
					 = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(org.apache.hadoop.ipc.protobuf.TestProtos
					.internal_static_hadoop_common_EmptyRequestProto_descriptor, new string[] {  });
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_descriptor
					 = org.apache.hadoop.ipc.protobuf.TestProtos.getDescriptor().getMessageTypes()[1
					];
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EmptyResponseProto_fieldAccessorTable
					 = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(org.apache.hadoop.ipc.protobuf.TestProtos
					.internal_static_hadoop_common_EmptyResponseProto_descriptor, new string[] {  });
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_descriptor
					 = org.apache.hadoop.ipc.protobuf.TestProtos.getDescriptor().getMessageTypes()[2
					];
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoRequestProto_fieldAccessorTable
					 = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(org.apache.hadoop.ipc.protobuf.TestProtos
					.internal_static_hadoop_common_EchoRequestProto_descriptor, new string[] { "Message"
					 });
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_descriptor
					 = org.apache.hadoop.ipc.protobuf.TestProtos.getDescriptor().getMessageTypes()[3
					];
				org.apache.hadoop.ipc.protobuf.TestProtos.internal_static_hadoop_common_EchoResponseProto_fieldAccessorTable
					 = new com.google.protobuf.GeneratedMessage.FieldAccessorTable(org.apache.hadoop.ipc.protobuf.TestProtos
					.internal_static_hadoop_common_EchoResponseProto_descriptor, new string[] { "Message"
					 });
				return null;
			}
		}
		// @@protoc_insertion_point(outer_class_scope)
	}
}
