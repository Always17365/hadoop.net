/*
* Licensed to the Apache Software Foundation (ASF) under one
*  or more contributor license agreements.  See the NOTICE file
*  distributed with this work for additional information
*  regarding copyright ownership.  The ASF licenses this file
*  to you under the Apache License, Version 2.0 (the
*  "License"); you may not use this file except in compliance
*  with the License.  You may obtain a copy of the License at
*
*       http://www.apache.org/licenses/LICENSE-2.0
*
*  Unless required by applicable law or agreed to in writing, software
*  distributed under the License is distributed on an "AS IS" BASIS,
*  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
*  See the License for the specific language governing permissions and
*  limitations under the License.
*/
using Sharpen;

namespace org.apache.hadoop.fs.contract
{
	/// <summary>Test Seek operations</summary>
	public abstract class AbstractContractOpenTest : org.apache.hadoop.fs.contract.AbstractFSContractTestBase
	{
		private org.apache.hadoop.fs.FSDataInputStream instream;

		protected internal override org.apache.hadoop.conf.Configuration createConfiguration
			()
		{
			org.apache.hadoop.conf.Configuration conf = base.createConfiguration();
			conf.setInt(org.apache.hadoop.fs.CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_KEY
				, 4096);
			return conf;
		}

		/// <exception cref="System.Exception"/>
		public override void teardown()
		{
			org.apache.hadoop.io.IOUtils.closeStream(instream);
			instream = null;
			base.teardown();
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testOpenReadZeroByteFile()
		{
			describe("create & read a 0 byte file");
			org.apache.hadoop.fs.Path path = path("zero.txt");
			org.apache.hadoop.fs.contract.ContractTestUtils.touch(getFileSystem(), path);
			instream = getFileSystem().open(path);
			NUnit.Framework.Assert.AreEqual(0, instream.getPos());
			//expect initial read to fail
			int result = instream.read();
			assertMinusOne("initial byte read", result);
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testFsIsEncrypted()
		{
			describe("create an empty file and call FileStatus.isEncrypted()");
			org.apache.hadoop.fs.Path path = path("file");
			org.apache.hadoop.fs.contract.ContractTestUtils.createFile(getFileSystem(), path, 
				false, new byte[0]);
			org.apache.hadoop.fs.FileStatus stat = getFileSystem().getFileStatus(path);
			NUnit.Framework.Assert.IsFalse("Expecting false for stat.isEncrypted()", stat.isEncrypted
				());
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testOpenReadDir()
		{
			describe("create & read a directory");
			org.apache.hadoop.fs.Path path = path("zero.dir");
			mkdirs(path);
			try
			{
				instream = getFileSystem().open(path);
				//at this point we've opened a directory
				NUnit.Framework.Assert.Fail("A directory has been opened for reading");
			}
			catch (java.io.FileNotFoundException e)
			{
				handleExpectedException(e);
			}
			catch (System.IO.IOException e)
			{
				handleRelaxedException("opening a directory for reading", "FileNotFoundException"
					, e);
			}
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testOpenReadDirWithChild()
		{
			describe("create & read a directory which has a child");
			org.apache.hadoop.fs.Path path = path("zero.dir");
			mkdirs(path);
			org.apache.hadoop.fs.Path path2 = new org.apache.hadoop.fs.Path(path, "child");
			mkdirs(path2);
			try
			{
				instream = getFileSystem().open(path);
				//at this point we've opened a directory
				NUnit.Framework.Assert.Fail("A directory has been opened for reading");
			}
			catch (java.io.FileNotFoundException e)
			{
				handleExpectedException(e);
			}
			catch (System.IO.IOException e)
			{
				handleRelaxedException("opening a directory for reading", "FileNotFoundException"
					, e);
			}
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testOpenFileTwice()
		{
			describe("verify that two opened file streams are independent");
			org.apache.hadoop.fs.Path path = path("testopenfiletwice.txt");
			byte[] block = org.apache.hadoop.fs.contract.ContractTestUtils.dataset(TEST_FILE_LEN
				, 0, 255);
			//this file now has a simple rule: offset => value
			org.apache.hadoop.fs.contract.ContractTestUtils.createFile(getFileSystem(), path, 
				false, block);
			//open first
			org.apache.hadoop.fs.FSDataInputStream instream1 = getFileSystem().open(path);
			int c = instream1.read();
			NUnit.Framework.Assert.AreEqual(0, c);
			org.apache.hadoop.fs.FSDataInputStream instream2 = null;
			try
			{
				instream2 = getFileSystem().open(path);
				NUnit.Framework.Assert.AreEqual("first read of instream 2", 0, instream2.read());
				NUnit.Framework.Assert.AreEqual("second read of instream 1", 1, instream1.read());
				instream1.close();
				NUnit.Framework.Assert.AreEqual("second read of instream 2", 1, instream2.read());
				//close instream1 again
				instream1.close();
			}
			finally
			{
				org.apache.hadoop.io.IOUtils.closeStream(instream1);
				org.apache.hadoop.io.IOUtils.closeStream(instream2);
			}
		}

		/// <exception cref="System.Exception"/>
		[NUnit.Framework.Test]
		public virtual void testSequentialRead()
		{
			describe("verify that sequential read() operations return values");
			org.apache.hadoop.fs.Path path = path("testsequentialread.txt");
			int len = 4;
			int @base = unchecked((int)(0x40));
			// 64
			byte[] block = org.apache.hadoop.fs.contract.ContractTestUtils.dataset(len, @base
				, @base + len);
			//this file now has a simple rule: offset => (value | 0x40)
			org.apache.hadoop.fs.contract.ContractTestUtils.createFile(getFileSystem(), path, 
				false, block);
			//open first
			instream = getFileSystem().open(path);
			NUnit.Framework.Assert.AreEqual(@base, instream.read());
			NUnit.Framework.Assert.AreEqual(@base + 1, instream.read());
			NUnit.Framework.Assert.AreEqual(@base + 2, instream.read());
			NUnit.Framework.Assert.AreEqual(@base + 3, instream.read());
			// and now, failures
			NUnit.Framework.Assert.AreEqual(-1, instream.read());
			NUnit.Framework.Assert.AreEqual(-1, instream.read());
			instream.close();
		}
	}
}
