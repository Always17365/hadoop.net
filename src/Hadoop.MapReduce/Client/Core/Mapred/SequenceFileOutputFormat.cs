using System;
using Org.Apache.Hadoop.Conf;
using Org.Apache.Hadoop.FS;
using Org.Apache.Hadoop.IO;
using Org.Apache.Hadoop.IO.Compress;
using Org.Apache.Hadoop.Mapreduce.Lib.Output;
using Org.Apache.Hadoop.Util;
using Sharpen;

namespace Org.Apache.Hadoop.Mapred
{
	/// <summary>
	/// An
	/// <see cref="OutputFormat{K, V}"/>
	/// that writes
	/// <see cref="Org.Apache.Hadoop.IO.SequenceFile"/>
	/// s.
	/// </summary>
	public class SequenceFileOutputFormat<K, V> : FileOutputFormat<K, V>
	{
		/// <exception cref="System.IO.IOException"/>
		public override RecordWriter<K, V> GetRecordWriter(FileSystem ignored, JobConf job
			, string name, Progressable progress)
		{
			// get the path of the temporary output file 
			Path file = FileOutputFormat.GetTaskOutputPath(job, name);
			FileSystem fs = file.GetFileSystem(job);
			CompressionCodec codec = null;
			SequenceFile.CompressionType compressionType = SequenceFile.CompressionType.None;
			if (GetCompressOutput(job))
			{
				// find the kind of compression to do
				compressionType = GetOutputCompressionType(job);
				// find the right codec
				Type codecClass = GetOutputCompressorClass(job, typeof(DefaultCodec));
				codec = ReflectionUtils.NewInstance(codecClass, job);
			}
			SequenceFile.Writer @out = SequenceFile.CreateWriter(fs, job, file, job.GetOutputKeyClass
				(), job.GetOutputValueClass(), compressionType, codec, progress);
			return new _RecordWriter_71(@out);
		}

		private sealed class _RecordWriter_71 : RecordWriter<K, V>
		{
			public _RecordWriter_71(SequenceFile.Writer @out)
			{
				this.@out = @out;
			}

			/// <exception cref="System.IO.IOException"/>
			public void Write(K key, V value)
			{
				@out.Append(key, value);
			}

			/// <exception cref="System.IO.IOException"/>
			public void Close(Reporter reporter)
			{
				@out.Close();
			}

			private readonly SequenceFile.Writer @out;
		}

		/// <summary>Open the output generated by this format.</summary>
		/// <exception cref="System.IO.IOException"/>
		public static SequenceFile.Reader[] GetReaders(Configuration conf, Path dir)
		{
			FileSystem fs = dir.GetFileSystem(conf);
			Path[] names = FileUtil.Stat2Paths(fs.ListStatus(dir));
			// sort names, so that hash partitioning works
			Arrays.Sort(names);
			SequenceFile.Reader[] parts = new SequenceFile.Reader[names.Length];
			for (int i = 0; i < names.Length; i++)
			{
				parts[i] = new SequenceFile.Reader(fs, names[i], conf);
			}
			return parts;
		}

		/// <summary>
		/// Get the
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile.CompressionType"/>
		/// for the output
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile"/>
		/// .
		/// </summary>
		/// <param name="conf">
		/// the
		/// <see cref="JobConf"/>
		/// </param>
		/// <returns>
		/// the
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile.CompressionType"/>
		/// for the output
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile"/>
		/// ,
		/// defaulting to
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile.CompressionType.Record"/>
		/// </returns>
		public static SequenceFile.CompressionType GetOutputCompressionType(JobConf conf)
		{
			string val = conf.Get(FileOutputFormat.CompressType, SequenceFile.CompressionType
				.Record.ToString());
			return SequenceFile.CompressionType.ValueOf(val);
		}

		/// <summary>
		/// Set the
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile.CompressionType"/>
		/// for the output
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile"/>
		/// .
		/// </summary>
		/// <param name="conf">
		/// the
		/// <see cref="JobConf"/>
		/// to modify
		/// </param>
		/// <param name="style">
		/// the
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile.CompressionType"/>
		/// for the output
		/// <see cref="Org.Apache.Hadoop.IO.SequenceFile"/>
		/// 
		/// </param>
		public static void SetOutputCompressionType(JobConf conf, SequenceFile.CompressionType
			 style)
		{
			SetCompressOutput(conf, true);
			conf.Set(FileOutputFormat.CompressType, style.ToString());
		}
	}
}
